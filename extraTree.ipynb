{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data...\n"
     ]
    }
   ],
   "source": [
    "#Import required libraries and read data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import random\n",
    "import math\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn import ensemble\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "print('Load data...')\n",
    "train = pd.read_csv(\"../train.csv\")\n",
    "#print(train.head())\n",
    "target = train['target'].values\n",
    "test = pd.read_csv(\"../test.csv\")\n",
    "id_test = test['ID'].values\n",
    "id_train = train['ID'].values\n",
    "#print(test.head())\n",
    "train = train.drop(['ID','target','v8','v23','v25','v31','v36','v37','v46','v51','v53','v54','v63','v73','v75','v79','v81','v82','v89','v92','v95','v105','v107','v108','v109','v110','v116','v117','v118','v119','v123','v124','v128'],axis=1)\n",
    "test = test.drop(['ID','v8','v23','v25','v31','v36','v37','v46','v51','v53','v54','v63','v73','v75','v79','v81','v82','v89','v92','v95','v105','v107','v108','v109','v110','v116','v117','v118','v119','v123','v124','v128'],axis=1)\n",
    "#print(train.columns.values)\n",
    "#print(test.columns.values)\n",
    "#print(train.dtypes)\n",
    "#print(test.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing...\n"
     ]
    }
   ],
   "source": [
    "#This part of code converts all factor variables into integers and adds -999 to NAs. I tried it to replicate this in R.\n",
    "print('Clearing...')\n",
    "for (train_name, train_series), (test_name, test_series) in zip(train.iteritems(),test.iteritems()):\n",
    "    if train_series.dtype == 'O':\n",
    "        #for objects: factorize\n",
    "        train[train_name], tmp_indexer = pd.factorize(train[train_name])\n",
    "        test[test_name] = tmp_indexer.get_indexer(test[test_name])\n",
    "        #but now we have -1 values (NaN)\n",
    "    else:\n",
    "        #for int or float: fill NaN\n",
    "        tmp_len = len(train[train_series.isnull()])\n",
    "        if tmp_len>0:\n",
    "            #print \"mean\", train_series.mean()\n",
    "            train.loc[train_series.isnull(), train_name] = -999 \n",
    "        #and Test\n",
    "        tmp_len = len(test[test_series.isnull()])\n",
    "        if tmp_len>0:\n",
    "            test.loc[test_series.isnull(), test_name] = -999\n",
    "\n",
    "#print(train.columns.values)\n",
    "#print(test.columns.values)\n",
    "#print(train.dtypes)\n",
    "#print(test.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training ', 1, 'of', 10.0)\n",
      "('CV Score ', 0.45387359886779105)\n",
      "('Training ', 2, 'of', 10.0)\n",
      "('CV Score ', 0.45893583585076941)\n",
      "('Training ', 3, 'of', 10.0)\n",
      "('CV Score ', 0.45587385112755741)\n",
      "('Training ', 4, 'of', 10.0)\n",
      "('CV Score ', 0.45100526784396433)\n",
      "('Training ', 5, 'of', 10.0)\n",
      "('CV Score ', 0.45024065190654033)\n",
      "('Training ', 6, 'of', 10.0)\n",
      "('CV Score ', 0.45204595757345939)\n",
      "('Training ', 7, 'of', 10.0)\n",
      "('CV Score ', 0.46667250723527198)\n",
      "('Training ', 8, 'of', 10.0)\n",
      "('CV Score ', 0.44954018906884252)\n",
      "('Training ', 9, 'of', 10.0)\n",
      "('CV Score ', 0.44838269244805679)\n",
      "('Training ', 10, 'of', 10.0)\n",
      "('CV Score ', 0.45881458243129569)\n",
      "Writing output files\n",
      "Done.....\n"
     ]
    }
   ],
   "source": [
    "#10 fold training and prediction.\n",
    "NFOLD = float(10)\n",
    "for i in range(1,(int(NFOLD)+1)):\n",
    "    st = math.ceil(len(train.axes[0])/NFOLD)\n",
    "    start = int((st*(i-1)) + 1)\n",
    "    end = int(min((st*i),len(train.axes[0])))\n",
    "    train_validation = train[start-1:end]\n",
    "    target_validation = target[start-1:end]\n",
    "    train_train = train.drop(train.index[start-1:end])\n",
    "    target_train = np.delete(target,range(start-1,end),axis=0)\n",
    "    random.seed(123)\n",
    "    X_train = train_train\n",
    "    X_val = train_validation\n",
    "    X_test = test\n",
    "    print('Training ',i,'of',NFOLD)\n",
    "    extc = ExtraTreesClassifier(n_estimators=850,max_features= 60,criterion= 'entropy',min_samples_split= 4,\n",
    "                            max_depth= 40, min_samples_leaf= 2, n_jobs = -1)\n",
    "    extc.fit(X_train,target_train)\n",
    "    \n",
    "    if i==1:\n",
    "        train_pred = extc.predict_proba(X_val)\n",
    "        print(\"CV Score \",log_loss(target_validation,train_pred))\n",
    "        train_pred = train_pred[:,1]\n",
    "        test_pred = extc.predict_proba(X_test)\n",
    "        test_pred = test_pred[:,1]\n",
    "    else:\n",
    "        trp = extc.predict_proba(X_val)\n",
    "        print(\"CV Score \",log_loss(target_validation,trp))\n",
    "        trp = trp[:,1]\n",
    "        tsp = extc.predict_proba(X_test)\n",
    "        tsp = tsp[:,1]\n",
    "        train_pred = np.concatenate((train_pred,trp),axis=0)\n",
    "        test_pred = test_pred+tsp\n",
    "\n",
    "print('Writing output files')\n",
    "test_pred = test_pred/NFOLD\n",
    "pd.DataFrame({\"ID\": id_test, \"PredictedProb\": test_pred}).to_csv('test_predictions_etc_v1.csv',index=False)\n",
    "pd.DataFrame({\"ID\": id_train, \"PredictedProb\": train_pred}).to_csv('train_predictions_etc_v1.csv',index=False)\n",
    "print('Done.....')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    }
   ],
   "source": [
    "#Extra tree regressor\n",
    "random.seed(123)\n",
    "X_train = train\n",
    "X_test = test\n",
    "print('Training...')\n",
    "extc = ExtraTreesClassifier(n_estimators=850,max_features= 60,criterion= 'entropy',min_samples_split= 4,\n",
    "                            max_depth= 40, min_samples_leaf= 2, n_jobs = -1)      \n",
    "\n",
    "extc.fit(X_train,target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
